{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moved-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas as mh\n",
    "import numpy as np\n",
    "from os import walk,path\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "imperial-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is the 10 imgs inside each of the folder\n",
    "# y is each of the folder name ..s1,s2.... common as .pgm\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "\n",
    "for dir_path,dir_names,file_names in walk('/home/sasikala/Downloads/att_faces'):\n",
    "#     print(file_names)\n",
    "    for fn in file_names:\n",
    "        if fn[-3:]=='pgm':\n",
    "            image_filename=path.join(dir_path,fn)\n",
    "            #print(image_filename)\n",
    "#reshape 2D TO 1D ,scaling,ad append to x\n",
    "            x.append(scale(mh.imread(image_filename,as_grey=True).reshape(10304).astype('float32')))\n",
    "            y.append(dir_path)\n",
    "#     print(file_names)\n",
    "#     print(dir_names)\n",
    "#     print(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pharmaceutical-trailer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dimension of the trianing data: (300, 10304)\n",
      "Reduced dimension of the trianing data: (300, 200)\n"
     ]
    }
   ],
   "source": [
    "#split data\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,random_state=42)\n",
    "\n",
    "#PCA\n",
    "x=np.array(x)\n",
    "pca=PCA(n_components=200)\n",
    "xtrain_reduced=pca.fit_transform(xtrain)\n",
    "xtest_reduced=pca.transform(xtest)\n",
    "\n",
    "#reduced the component into 200\n",
    "print('original dimension of the trianing data:',xtrain.shape)\n",
    "print('Reduced dimension of the trianing data:',xtrain_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "corrected-belfast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='ovr', random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create model using multiclass\n",
    "\n",
    "model=LogisticRegression(multi_class='ovr',random_state=42)\n",
    "model.fit(xtrain_reduced,ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "balanced-receptor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.95 [0.95       0.96666667 0.95       0.93333333 0.95      ]\n"
     ]
    }
   ],
   "source": [
    "cross_vald=cross_val_score(model,xtrain_reduced,ytrain)\n",
    "\n",
    "# cross_vald\n",
    "print('Cross validation score:',np.mean(cross_vald),cross_vald)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sixth-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        precision    recall  f1-score   support\n",
      "\n",
      " /home/sasikala/Downloads/att_faces/s1       1.00      1.00      1.00         2\n",
      "/home/sasikala/Downloads/att_faces/s10       1.00      1.00      1.00         2\n",
      "/home/sasikala/Downloads/att_faces/s11       1.00      1.00      1.00         7\n",
      "/home/sasikala/Downloads/att_faces/s12       1.00      1.00      1.00         2\n",
      "/home/sasikala/Downloads/att_faces/s13       1.00      1.00      1.00         3\n",
      "/home/sasikala/Downloads/att_faces/s14       1.00      1.00      1.00         2\n",
      "/home/sasikala/Downloads/att_faces/s15       1.00      1.00      1.00         4\n",
      "/home/sasikala/Downloads/att_faces/s16       1.00      1.00      1.00         1\n",
      "/home/sasikala/Downloads/att_faces/s17       1.00      1.00      1.00         4\n",
      "/home/sasikala/Downloads/att_faces/s18       1.00      1.00      1.00         1\n",
      "/home/sasikala/Downloads/att_faces/s19       1.00      1.00      1.00         3\n",
      " /home/sasikala/Downloads/att_faces/s2       1.00      1.00      1.00         3\n",
      "/home/sasikala/Downloads/att_faces/s20       1.00      1.00      1.00         1\n",
      "/home/sasikala/Downloads/att_faces/s21       1.00      1.00      1.00         2\n",
      "/home/sasikala/Downloads/att_faces/s22       1.00      1.00      1.00         2\n",
      "/home/sasikala/Downloads/att_faces/s23       1.00      0.75      0.86         4\n",
      "/home/sasikala/Downloads/att_faces/s24       1.00      1.00      1.00         4\n",
      "/home/sasikala/Downloads/att_faces/s25       1.00      1.00      1.00         4\n",
      "/home/sasikala/Downloads/att_faces/s26       1.00      1.00      1.00         1\n",
      "/home/sasikala/Downloads/att_faces/s27       1.00      1.00      1.00         1\n",
      "/home/sasikala/Downloads/att_faces/s28       0.80      1.00      0.89         4\n",
      "/home/sasikala/Downloads/att_faces/s29       1.00      1.00      1.00         1\n",
      " /home/sasikala/Downloads/att_faces/s3       1.00      1.00      1.00         2\n",
      "/home/sasikala/Downloads/att_faces/s30       1.00      1.00      1.00         3\n",
      "/home/sasikala/Downloads/att_faces/s31       1.00      1.00      1.00         2\n",
      "/home/sasikala/Downloads/att_faces/s32       1.00      1.00      1.00         1\n",
      "/home/sasikala/Downloads/att_faces/s33       1.00      1.00      1.00         3\n",
      "/home/sasikala/Downloads/att_faces/s34       1.00      1.00      1.00         1\n",
      "/home/sasikala/Downloads/att_faces/s35       0.67      0.67      0.67         3\n",
      "/home/sasikala/Downloads/att_faces/s36       1.00      1.00      1.00         1\n",
      "/home/sasikala/Downloads/att_faces/s37       1.00      1.00      1.00         3\n",
      "/home/sasikala/Downloads/att_faces/s38       0.67      1.00      0.80         2\n",
      " /home/sasikala/Downloads/att_faces/s4       1.00      1.00      1.00         3\n",
      "/home/sasikala/Downloads/att_faces/s40       1.00      0.50      0.67         2\n",
      " /home/sasikala/Downloads/att_faces/s5       1.00      0.80      0.89         5\n",
      " /home/sasikala/Downloads/att_faces/s6       1.00      1.00      1.00         3\n",
      " /home/sasikala/Downloads/att_faces/s7       1.00      1.00      1.00         2\n",
      " /home/sasikala/Downloads/att_faces/s8       1.00      1.00      1.00         2\n",
      " /home/sasikala/Downloads/att_faces/s9       0.80      1.00      0.89         4\n",
      "\n",
      "                              accuracy                           0.96       100\n",
      "                             macro avg       0.97      0.97      0.97       100\n",
      "                          weighted avg       0.97      0.96      0.96       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(xtest_reduced)\n",
    "print(classification_report(ytest,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-pasta",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
